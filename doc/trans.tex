\documentclass{article}
\bibliographystyle{unsrt}
\input{defs.tex}
\input{notation.tex}
\begin{document}

\newcommand\authorstring{
Ian Holmes$^{1,\ast}$ \\
\textbf{1} Department of Bioengineering, University of California, Berkeley, CA, USA \\
$\ast$ E-mail: ihh@berkeley.edu
}

\newcommand\titlestring{Transducer codes for DNA}
\newcommand\shorttitlestring{Transducer codes for DNA}
\markboth{\shorttitlestring}{\shorttitlestring}
\begin{flushleft}
{\Large \textbf{\titlestring} } \\
\authorstring
\end{flushleft}
%\section*{Abstract}
%\paragraph{Keywords:}
%\tableofcontents

\section*{Introduction}

Transducers \cite{MohriPereiraRiley2000,WikipediaTransducers}

In bioinformatics:
protein classification \cite{EskinEtAl2000},
phylogenetics \cite{PatenEtAl2008,WestessonEtAlArxiv2012,WestessonEtAl2012},
cancer informatics \cite{SchwarzEtAl2014}

Arithmetic coding \cite{Mackay2003}

DNA storage \cite{ChurchEtAl2012,GoldmanEtAl2013}.
Codes \cite{YazdiEtAl2015}


\section*{Methods}

\subsection*{Weighted finite-state transducers}

Following \cite{MohriPereiraRiley2000}:
Assume a general semiring
$\semiring=(\srset,\srplus,\srtimes,\srplusid,\srtimesid)$
which for our purposes is typically the probability semiring
$(\Re,+,\times,0,1)$
or the tropical semiring
$(\Re_{+} \cup {\infty},\min,+,\infty,0)$.

A weighted finite-state transducer is defined as a tuple
$T = (\inalph,\outalph,\states,\transitions,\initstate,\finalstate)$
consisting of an input alphabet $\inalph$,
an output alphabet $\outalph$ (both alphabets being finite sets),
a finite set of states $\states$,
a finite set of transitions
$\transitions \subseteq \states \times \maybe{\inalph} \times \maybe{\outalph} \times \srset \times \states$,
an initial state $\initstate \in \states$
and a final state $\finalstate \in \states$.

The transducer $T$ can be thought of as an edge-labelled directed graph
where each state is a vertex
and each transition
$\trans = (\src[\trans],\inlab[\trans],\outlab[\trans],\weight[\trans],\dest[\trans]) \in \transitions$
is an edge from state $\src[\trans]$ to state $\dest[\trans]$
with input label $\inlab[\trans]$,
output label $\outlab[\trans]$
and weight $\weight[\trans]$.

A path in $T$ is a series of transitions that form a path in this graph.
The input sequence and output sequence for a path are the concatenation of (respectively)
the input and output labels of the transitions in the path.
The path weight is the $\srtimes$-product of the transition weights.
A successful path is one that starts in $\initstate$ and ends in $\finalstate$.
The transduction weight for a given input sequence $\inseq \in \inseqs$
and output sequence $\outseq \in \outseqs$
is the $\srplus$-sum of all successful paths
having $\inseq$ as the input sequence
and $\outseq$ as the output sequence.
Thus $T$ provides a mapping
$\tfunc{T}:(\kleene{\inalph} \times \kleene{\outalph}) \to \srset$
from sequence-pairs to weights.
We call this mapping $\tfunc{T}$ the transducer function.
For a given pair of sequences $(\inseq,\outseq)$
and a semiring wherein $\srplus$ and $\srtimes$ are amortized-constant resource operations,
it can be evaluated in time $\bigo(|\inseq| \cdot |\outseq| \cdot |\transitions|)$
and memory $\bigo(|\inseq| \cdot |\outseq| \cdot |\states|)$
by dynamic programming,
analogously to the Forward algorithm in the probabilistic semiring
or the Viterbi algorithm in the tropical semiring
\cite{Durbin98}.

A state $\state \in \states$ has past context $\inseqpast$ if every path from $\initstate$ to $\state$ has an input sequence with suffix $\inseqpast$,
and future context $\inseqnext$ if every path from $\state$ to $\finalstate$ has an input sequence with prefix $\inseqnext$.

\subsection*{Transducer composition}

Given transducers
 $R = (\inalph, \somealph, \states_R, \transitions_R, \initstate_R, \finalstate_R)$ and
 $S = (\somealph, \outalph, \states_S, \transitions_S, \initstate_S, \finalstate_S)$
where $R$'s output alphabet is the same as $S$'s input alphabet,
we can readily find a composite transducer
 $T = R \transcomp S = (\inalph, \outalph, \states_T, \transitions_T, \initstate_T, \finalstate_T)$
such that, if $\tfunc{R}$, $\tfunc{S}$ and $\tfunc{T}$ are the corresponding transducer functions,
then
\[
\forall \inseq \in \inseqs, \outseq \in \outseqs:
\quad
\tfunc{T}(\inseq,\outseq) = \srsum_{\someseq \in \someseqs} \tfunc{R}(\inseq,\someseq) \tfunc{R}(\someseq,\outseq)
\]
that is, $T$ models the feeding of $R$'s output into $S$'s input
(and this intermediate sequence is then summed out---i.e. marginalized, if we are in the probabilistic semiring).

Loosely speaking, we can construct $T$ using the following recipe:
\begin{itemize}
\item Each $T$-state corresponds to a pair of $R$- and $S$-states,
so $\state_T = (\state_R, \state_S)$
and $\states_T \subseteq \states_R \times \states_S$.
\item The initial $T$-state $\initstate_T=(\initstate_R,\initstate_S)$ pairs the initial states of $R$ and $S$.
\item The final $T$-state $\finalstate_T=(\finalstate_R,\finalstate_S)$ pairs the final states of $R$ and $S$.
\item $T$-transitions
$\trans_T = ((\src_R,\src_S),\inlab,\outlab,\weight_T,(\dest_R,\dest_S))$
represent (summaries of sets of) synchronized pairs of $R$-transitions
$\trans_R = (\src_R,\inlab,\midlab,\weight_R,\dest_R)$
and $S$-transitions
$\trans_S = (\src_S,\midlab,\outlab,\weight_S,\dest_S)$
which share the same intermediate label $\midlab$.
The composite transition weight $\weight_T$ is the product $\weight_R \srtimes \weight_S$,
or the sum over such products if there are multiple transition-pairs $(\trans_R,\trans_S)$
consistent with a given $\trans_T$
(which, in the probabilistic semiring, is equivalent to marginalizing out $\midlab$).
\item Some additional manipulation is required to synchronize
transitions involving empty input labels (``insertions''),
empty output labels (``deletions''),
or both (``null transitions'').
For example, we can require that $S$-transitions accepting incoming symbols
all originate from ``ready'' states which have no outgoing insertions.
(If $S$ does not comply with this stipulation then we can easily derive a transducer
with the same transducer function $\tfunc{S}$ that does comply.)
\end{itemize}

Examples of this construction are given in \cite{MohriPereiraRiley2000} and \cite{WestessonEtAlArxiv2012,WestessonEtAl2012}.

\subsection*{De Bruijn graphs}

The $\kmerlen$-dimensional De Bruijn graph over an alphabet $\somealph$ of cardinality $M$
is a directed graph with $M^\kmerlen$ vertices,
corresponding to all possible $\kmerlen$-symbol strings
$\sym_1 \sym_2 \ldots \sym_\kmerlen \in \somealph^\kmerlen$.
There is an edge $u \to v$ between any two vertices
$u=\sym_1 \sym_2 \ldots \sym_\kmerlen$ and $v=\sym_2 \ldots \sym_\kmerlen \sym_{\kmerlen+1}$
that overlap by $\kmerlen-1$ symbols; this edge is labeled with symbol $\sym_{\kmerlen+1}$ (the last symbol of $v$).
Thus, each vertex has $M$ incoming and $M$ outgoing edges \cite{DeBruijn1946,PevznerEtAl2001}.
Denote this graph by $\debruijngraph = (\debruijnvertices,\debruijnedges)$.

\subsection*{A transducer for encoding signals as DNA without short repeats or reserved words}

Let $\nucalph = \{ \mbox{A}, \mbox{C}, \mbox{G}, \mbox{T} \} $ be the nucleotide alphabet and define the complement $\comp{x}$ of a nucleotide symbol $x$,
and the reverse complement $\revcomp{\someseq}$ of a nucleotide sequence $\someseq$, in the usual way.

A direct tandem repeat of length $k$ is a nucleotide sequence followed by an exact copy of itself, $\someseq \someseq$, where the length of each copy is $\seqlen{\someseq}=k$
(note this includes repeated single nucleotides when $k=1$).
Similarly, a direct inverted repeat of length $k$ is a $k$-nucleotide sequence followed by its reverse complement, $\someseq \revcomp{\someseq}$.
A local inverted repeat of length $k$ and separation $l$ is a $k$-nucleotide sequence, followed an $l$-nucleotide sequence, followed by the reverse complement
of the first sequence; that is, $\someseq \otherseq \revcomp{\someseq}$, where $\seqlen{\someseq}=k$ and $\seqlen{\otherseq}=l$.

Start with $\debruijngraph$, the $\kmerlen$-dimensional De Bruijn graph over $\nucalph$.
Delete all nodes corresponding to sequences that contain substrings which are
direct tandem repeats of any length,
direct inverted repeats of length $\geq 2$,
or local inverted repeats of length $\geq \invreplen$ and separation $\geq 2$.
Denote the resulting graph by $\norepgraph = (\norepvertices,\norepedges)$.

Let $A \subset \norepvertices$ be a set of vertices to avoid,
let $D \in A$ be a target vertex,
and denote by $\prequels(D,A,N) \subset \norepvertices$
the set of all vertices
from which there exists a length-$N$ path to $D$
that does not pass through any of the vertices in $A$
(although the path is allowed to originate from one of those vertices).
Define $\stepsto(D,A)$ to be the smallest value of $N$ for which $\prequels(D,A,N) = \norepvertices$,
if such a value of $N$ exists; otherwise, let $\stepsto(D,A)$ be $\infty$.
We can find $\prequels(D,A,N)$ from $\prequels(D,A,N-1)$ by recursive backtracking,
and so determine in $M$ steps whether $\stepsto(D,A) \leq M$.

We now allocate $\ncontrols$ ``control words'': $\kmerlen$-mers that in our transducer
will be unreachable except by specially constructed paths of uniform length.
Specifically, we seek an indexed set of vertices
$\controlset = \{ \controlword_1, \controlword_2 \ldots \controlword_{\ncontrols} \}$
such that $\stepsto(\controlword_n,\controlset) \leq M$ for all $n$
and some value of $M$ (e.g. $M = 2\kmerlen$).
Our implementation finds this list $\controlset$ by brute-force recursive search
and further attempts to maximize the shortest Hamming distance between any two control words in $\controlset$.
Note that there is a ceiling to the number of control words that may be found
for any given value of $\kmerlen$ (and $\invreplen$),
though this ceiling grows rather rapidly with $\kmerlen$.
In practice we only need a few control words for most purposes.

Having designated some $\kmerlen$-mers as control words via analysis of $\norepgraph$,
we now construct a new graph $\controlgraph$
in which the control words are unreachable from the other words
except by paths that we construct.
Starting with graph $\norepgraph$, delete all incoming transitions to control words $\controlword_n \in \controlset$,
rendering them unreachable,
and prune the graph of any other nodes that become unreachable as a result.
Next, for every control word $\controlword_n \in \controlset$
and every path length $1 \leq k < \stepsto(\controlword_n,\controlset)$,
we create a new vertex set $\controlbridges{n,k}$
with a one-to-one correspondence to $\prequels(\controlword_n,\controlset,k)$.
We connect the newly-added vertices such that there is an edge from
$u \in \controlbridges{n,k}$ to $v \in \controlbridges{n,k-1}$
for every corresponding edge $(u',v') \in \norepedges$ between
$u' \in \prequels(\controlword_n,\controlset,k)$
and
$v' \in \prequels(\controlword_n,\controlset,k-1)$.
We also add edges from
$u \in \norepvertices$ to $v \in \controlbridges{n,\stepsto(\controlword_n,\controlset)}$
for the first steps in the paths to control words,
as well as edges from
$u \in \controlbridges{n,1}$ to $\controlword$
for the final steps.
In each case the newly-added edge is copied from a corresponding edge in $\norepedges$
and inherits the same edge label.

It is useful to force the transducer to start with a particular control word $\initword$
and end with a particular control word $\finalword$.
To guarantee this we add a chain of initial vertices and edges leading from source vertex to the initial control word,
$\initvertex{0} \to \initvertex{1} \to \initvertex{2} \to \ldots \to \initvertex{\kmerlen-1} \to \initword$,
with each transition labeled with consecutive symbols from the initial control word.
For symmetry and representational convenience, we also add a chain of final vertices and edges leading
from the final control word to a sink vertex,
$\finalword \to \finalvertex{\kmerlen-1} \to \ldots \to \finalvertex{2} \to \finalvertex{1} \to \finalvertex{0}$.
These final transitions are labeled with $\emptystring$'s.

We have now constructed the graph $\controlgraph$ from which our transducer $\controlmachine$
is derived via the following recipe:
\begin{itemize}
\item Every vertex in $\controlgraph$ is a state in $\controlmachine$.
The initial and final vertices of $\controlgraph$ are the initial and final states of $\controlmachine$.
\item Every edge in $\controlgraph$ is a unit-weight transition in $\controlmachine$.
The output label of the transition is the label of the edge.
\item The input label of each transition is determined as follows:
\begin{itemize}
\item For states in $\norepvertices$ with two outgoing transitions to other states in $\norepvertices$, those transitions are input-labeled with the binary digits \bit{0} and \bit{1}.
\item For states in $\norepvertices$ with three outgoing transitions to other states in $\norepvertices$, those transitions are input-labeled with the trinary digits \trit{0}, \trit{1} and \trit{2}.
\item For states in $\norepvertices$ with four outgoing transitions to other states in $\norepvertices$, those transitions are input-labeled with the quaternary digits \quat{0}, \quat{1}, \quat{2} and \quat{3}.
\item Transitions from states in $\norepvertices$ to states in $\controlbridges{n,\stepsto(\controlword_n,\controlset)}$,
which begin a path to the $i$'th control word $\controlword_n$,
are input-labeled with the special control digit \controldigit{n}.
\item All other transitions have input label $\emptystring$.
\end{itemize}
\end{itemize}

Thus, the input alphabet of $\controlmachine$
is $\{ \bit{0}, \bit{1},
       \trit{0}, \trit{1}, \trit{2},
       \quat{0}, \quat{1}, \quat{2}, \quat{3},
       \controlword_1 \ldots \controlword_{\ncontrols} \}$.

\subsection*{The delayed transducer}

\subsection*{A transducer that periodically flushes its output}

\subsection*{A transducer that converts a binary sequence into a mixture of binary, trinary and quaternary}



\bibliography{trans}



\end{document}
